\documentclass[letterpaper,12pt]{article}
\usepackage{array}
\usepackage{threeparttable}
\usepackage{geometry}
\geometry{letterpaper,tmargin=1in,bmargin=1in,lmargin=1.25in,rmargin=1.25in}
\usepackage{fancyhdr,lastpage}
\pagestyle{fancy}
\lhead{}
\chead{}
\rhead{}
\lfoot{}
\cfoot{}
\rfoot{\footnotesize\textsl{Page \thepage\ of \pageref{LastPage}}}
\renewcommand\headrulewidth{0pt}
\renewcommand\footrulewidth{0pt}
\usepackage[format=hang,font=normalsize,labelfont=bf]{caption}
\usepackage{listings}
\lstset{frame=single,
  language=Python,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  breaklines=true,
  breakatwhitespace=true
  tabsize=3
}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{harvard}
\usepackage{setspace}
\usepackage{float,color}
\usepackage[pdftex]{graphicx}
\usepackage{hyperref}
\hypersetup{colorlinks,linkcolor=red,urlcolor=blue}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{derivation}{Derivation} % Number derivations on their own
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}{Proposition} % Number propositions on their own
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
%\numberwithin{equation}{section}
\bibliographystyle{aer}
\newcommand\ve{\varepsilon}
\newcommand\boldline{\arrayrulewidth{1pt}\hline}


\begin{document}

\begin{flushleft}
  \textbf{\large{Math Problem Set \#3}} \\
  Charlie Walker
\end{flushleft}

\vspace{5mm}

\noindent\textbf{4.2}\\
\begin{equation*}
D= \begin{bmatrix}
	0 & 1 & 0\\
	0 & 0 & 2\\
	0 & 0 & 0
\end{bmatrix}
\end{equation*}
$D$ is upper triangular, so the eigenvalues are its diagonal entries $\implies D$ has no eigenvalues. Algebraic and geometric multiplicities are both zero.\\

\noindent\textbf{4.4}\\
(i) For non-zero $x \in V, \lambda \in \mathbb{F}$,
\begin{align*}
Ax &= \lambda x\\
(Ax)^H &= (\lambda x)^H\\
x^HA^H &= x^H\lambda ^H
\end{align*}
Post-multiplying by $x$,
\begin{align*}
x^HA^Hx &= x^H\lambda^Hx
\end{align*}
Since A is Hermitian, $A^H = A$,
\begin{align*}
\implies x^HAx &= x^H\lambda^Hx\\
x^H\lambda x &= \lambda^H x^Hx\\
\lambda x^H x &= \lambda^H x^H x\\
\implies \lambda &= \lambda^H
\end{align*}
Thus, $\lambda \in \mathbb{R}$.\\

(ii) $\langle Ax, x \rangle = \langle \lambda x, x \rangle = \bar{\lambda} \|x\|^2 = \langle x, A^H x \rangle = - \langle x, Ax \rangle = -\lambda \|x\|^2 \implies \bar{\lambda} = -\lambda \implies \lambda$ is imaginary. \\

\noindent\textbf{4.6}\\
Take an upper triangular matrix $A \in M_n(\mathbb{F})$,
\begin{equation*}
A= \begin{bmatrix}
	\lambda_1 & & & \\
	& \lambda_2 & & \\
	& & \ddots & \\
	& & & \lambda_n\\
\end{bmatrix}
\end{equation*}
With arbitrary entries above the diagonal, and zeros below. Take any $\lambda \in \mathbb{F}$. Then,
\begin{equation*}
\lambda I - A = \begin{bmatrix}
	\lambda - \lambda_1 & & & \\
	& \lambda - \lambda_2 & & \\
	& & \ddots & \\
	& & & \lambda - \lambda_n\\
\end{bmatrix}
\end{equation*}
$\lambda$ is an eigenvalue of $A$ if and only if $\lambda I - A$ is not invertible. Equivalently, for upper triangular matrices, $A$ is invertible if and only if all the diagonal entries are nonzero. Thus, $\lambda$ is an eigenvalue if and only if it equals one of the numbers $\lambda_1, \lambda_2 \cdots \lambda_n$. Thus, $\lambda_1, \lambda_2 \cdots \lambda_n$ are the eigenvalues of $A$.\\

\noindent\textbf{4.8}\\
(i) $S = \{\sin(x), \cos(x), \sin(2x), \cos(2x)\}$ forms a basis if it's linearly independent, and if every vector $v \in V$ can be expressed as a linear combination of the elements of $S$. \\

\noindent(ii) \begin{equation*}
D = \begin{bmatrix}
	0 & 1 & 0 & 0\\
	1 & 0 & 0 & 0\\
	0 & 0 & 0 & 2\\
	0 & 0 & 2 & 0
\end{bmatrix}\\
\end{equation*}

\noindent(iii) The kernel of $D$ is one of them. \\

\noindent\textbf{4.13}\\
\begin{align*}
A&=\begin{bmatrix}
	0.8 & 0.4\\
	0.2 & 0.6 \\
\end{bmatrix}\\
p(\lambda) &= \det(\lambda I - A)\\
&= \begin{vmatrix}
	\lambda - 0.8 & -0.4\\
	-0.2 & \lambda - 0.6 \\
\end{vmatrix}\\
\implies \sigma(A) &= \{1, 0.4\}
\end{align*}
The eigenvectors corresponding to eigenvalues 1 and 0.4 are $\begin{bmatrix}2 &1\end{bmatrix}^T$ and $\begin{bmatrix}-1& 1\end{bmatrix}^T$, respectively. Thus, the transition matrix is:
\begin{equation*}
P=\begin{bmatrix}
	2 & -1\\
	1 & 1\\
\end{bmatrix}
\end{equation*}\\

\noindent\textbf{4.15}\\
Let set $S = \{x_1, x_2, \cdots , x_n\}$ form an eigenbasis of $A \in M_n(\mathbb{F})$. Because $A$ is semisimple, it is diagonalizable. Let $D = P^{-1}AP$ be the diagonal representation of $A$. Thus,
\begin{align*}
f(A) &= a_0I + a_1A + \cdots + a_nA^n \\
&= a_0I + a_1P^{-1}DP + \cdots + a_n P^{-1}D^nP
\end{align*}
The eigenvalues of $D$ are the entries along its diagonal. For $i = 1, \cdots , n$,
\begin{align*}
\lambda_i &= a_0 + a_1 \lambda_i + \cdots + a_n \lambda_i^n\\
&= f(\lambda_i)
\end{align*}
as desired.\\

\noindent\textbf{4.16}\\
(i) \begin{align*}
A&=\begin{bmatrix}
	0.8 & 0.4\\
	0.2 & 0.6 \\
\end{bmatrix}\\
&= \begin{bmatrix}
	2 & -1 \\
	1 & 1 \\
\end{bmatrix}^{-1}
B \begin{bmatrix}
	2 & -1\\
	1 & 1 \\
\end{bmatrix}\\
&= \begin{bmatrix}
	2 & -1 \\
	1 & 1 \\
\end{bmatrix}^{-1}
 \begin{bmatrix}
	1 & 0\\
	0 & 0.4\\
\end{bmatrix} \ \begin{bmatrix}
	2 & -1\\
	1 & 1 \\
\end{bmatrix}\\
\implies A^n &= \begin{bmatrix}
	1.5 & -1 \\
	-0.5 & 2 \\
\end{bmatrix}
\begin{bmatrix}
	1 & 0\\
	0 & 0.4^n\\
\end{bmatrix} \begin{bmatrix}
	2 & -1\\
	1 & 1 \\
\end{bmatrix}\\
\end{align*}
As $n \rightarrow \infty, 0.4 \rightarrow 0$.
\begin{align*}
\implies \lim_{n \rightarrow \infty} A^n &=
\begin{bmatrix}
	1.5 & -1 \\
	-0.5 & 2 \\
\end{bmatrix}
\begin{bmatrix}
	1 & 0\\
	0 & 0\\
\end{bmatrix} \begin{bmatrix}
	2 & -1\\
	1 & 1 \\
\end{bmatrix}\\
&= \begin{bmatrix}
	1.5 & 0 \\
	-0.5 & 0 \\
\end{bmatrix}\\
&= \begin{bmatrix}
	3 & -1.5 \\
	-1 & 0.5 \\
\end{bmatrix}\\
\implies \| \lim_{n \rightarrow \infty} A^n \|_1 &= 4
\end{align*}\\

\noindent(ii) \begin{align*}
\| \lim_{n \rightarrow \infty} A^n \|_{\infty} &= 4.5\\
\| \lim_{n \rightarrow \infty} A^n \|_{F} &= \sqrt{tr(A^TA)}\\
&= \sqrt{12.5}\\
\end{align*}\\
Yes, it's changing, but I think I messed something up. \textbf{TODO: FIX THIS}\\

\noindent (iii) Let matrix $B = 3I + 5A + A^3$, with $A$ as defined above.
\begin{align*}
\sigma(A) &= \{1, 0.4\}\\
\sigma(B) &= \{3 + 5(1) + (1)^3, 3 + 5(0.4) + (0.4)^3\}\\
&= \{9, 5.064\}
\end{align*}\\

\noindent\textbf{4.18}
\begin{equation*}
Ax = \lambda x
\end{equation*}
Left-multiplying,
\begin{align*}
x^TAx &= x^T \lambda x \\
x^TAx &= \lambda x^T x\\
\implies x^TA &= \lambda x^T
\end{align*}
\textbf{TODO: actually solve this.}

\end{document}
